\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin = 0.8in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage{float}
\usepackage{pythonhighlight}
\usepackage{array}


\title{RBE549 - Final Exam}
\author{Keith Chester}
\date{Due date: December 12, 2022}

\begin{document}

\maketitle

\section*{Problem 1}

In this problem, we are tasked with solving an iterative optical flow problem. To compute optical flow, we learned an interative method to update $u(x,y)$, $v(x,y)$ at each iteration, according to:

\begin{equation}
    \begin{bmatrix}
        u(x,y) \\ v(x,y)
    \end{bmatrix}^2 = \begin{bmatrix}
        \lambda I_x ^2 + 4 && \lambda I_x I_y \\
        \lambda I_x I_y && \lambda I_y^2 + 4
    \end{bmatrix}^{-1}
    \begin{bmatrix}
        \sum_{n\epsilon \textit{neighbors}(x,y)} u^{old}(n)-\lambda I_x I_t \\
        \sum_{n\epsilon \textit{neighbors}(x,y)} v^{old}(n)-\lambda I_y I_t \\
    \end{bmatrix}
\end{equation}

We are asked to consider a local coordinate frame $(x',y')$ where $x'$ is aligned with the image gradient and $y'$ is perpendicular to the image gradient. Likewise, $(u',v')=(\frac{dx'}{dt}, \frac{dy'}{dt})$ are the image velocities in this frame. In this coordinate frame,

\begin{equation}
    I_{x'} = \sqrt{I_x^2 + I_y^2}\textit{ and } I_{y'} = 0
\end{equation}

We wish to show that the update equations:

\begin{equation}
    \begin{bmatrix}
        u'(x,y) \\ v'(x,y)
    \end{bmatrix}^2 = \begin{bmatrix}
        \lambda I_{x'}^2 + 4 && \lambda I_{x'} I_{y'} \\
        \lambda I_{x'} I_{y'} && \lambda I_{y'}^2 + 4
    \end{bmatrix}^{-1}
    \begin{bmatrix}
        \sum_{n\epsilon \textit{neighbors}(x,y)} u'^{old}(n)-\lambda I_{x'} I_t \\
        \sum_{n\epsilon \textit{neighbors}(x,y)} v'^{old}(n)-\lambda I_{y'} I_t \\
    \end{bmatrix}
\end{equation}

\noindent ...can reduce to

\begin{equation}
    u'^{new}(x,y)=\bar{u}'^{old}- \frac{I_{x'}^2\bar{u}'^{old} + I_{x'}I_t}{I_{x'}^2+\frac{4}{\lambda}}
\end{equation}

\begin{equation}
    v'^{new}(x,y)=\bar{v}'^{old}
\end{equation}

\noindent. To do this, we first expand our second term to an equivalnet form to make matters easier for us to work with. Specifically, the inverse of a $2x2$ matrix is:

\begin{equation}
    \begin{bmatrix}
        a & b \\
        c & d
    \end{bmatrix}^{-1} =
    \frac{1}{ad-bc}
    \begin{bmatrix}
        d & -b \\
        -c & a
    \end{bmatrix}
\end{equation}

\noindent ...and thus...

\begin{equation}
    \begin{bmatrix}
        \lambda I_{x'}^2 + 4 & \lambda I_{x'} I_{y'} \\
        \lambda I_{x'} I_{y'} & \lambda I_{y'}^2 + 4
    \end{bmatrix}^{-1} =
    \frac{1}{(\lambda I_{x'}^2 + 4)(\lambda I_{y'}^2 + 4)- \lambda I_{x'} I_{y'} \lambda I_{x'} I_{y'}}
    \begin{bmatrix}
        \lambda I_{y'}^2 + 4 & -\lambda I_{x'} I_{y'} \\
        -\lambda I_{x'} I_{y'} & \lambda I_{y'}^2 + 4
    \end{bmatrix}
\end{equation}

\noindent ...which simplifies to:

\begin{equation}
    \frac{1}{4 \lambda I_{x'}^2 + 4\lambda I_{y'}^2 + 16}
    \begin{bmatrix}
        \lambda I_{y'}^2 + 4 & -\lambda I_{x'} I_{y'} \\
        -\lambda I_{x'} I_{y'} & \lambda I_{x'}^2 + 4
    \end{bmatrix}
\end{equation}

\noindent This in turn leads us to an expanded view from earlier:

\begin{equation}
    u'^{new}(x,y) =
    \frac{1}{4(\lambda I_{x'}^2 + \lambda I_{y'}^2 + 4)}
    \begin{bmatrix}
        \lambda I_{y'}^2 + 4 & -\lambda I_{x'} I_{y'}
    \end{bmatrix}
    \begin{bmatrix}
        4\bar{u}'^{old}-\lambda I_{x'} I_t \\
        4\bar{v}'^{old}-\lambda I_{y'} I_t \\
    \end{bmatrix}
\end{equation}

\noindent ...We can then expand it into this:

\begin{equation}
    u'^{new}(x,y) = \frac{1}{4(\lambda I_{x'}^2 + \lambda I_{y'}^2 + 4)}
    \big(
    (\lambda I_{y'}^2 +4)(4\bar{u}'^{old}-\lambda I_{x'} I_t) - (\lambda I_{x'} I_{y'})(4\bar{v}'^{old}+\lambda I_{x'} I_{y'} \lambda I_{y'} I_t)
    )
\end{equation}

\begin{equation}
    u'^{new}(x,y) = \frac
    {\lambda I_{y'}^2 4\bar{u}^{old}-\lambda I_{y'}^2 \lambda I_{x'} I_t + 16\bar{u}'^{old}-4\lambda I_{x'} I_t-(\lambda I_{x'} I_{y'})4\bar{v}'^{old}+\lambda^2 I_{y'}^2 I_{x'} I_t}
    {4(\lambda I_{x'}^2 + \lambda I_{y'}^2 + 4)}
\end{equation}

\begin{equation}
    u'^{new}(x,y) = \frac
    {4(\lambda I_{y'}^2 \bar{u}'^{old} + 4\bar{u}'^{old} - \lambda I_{x'} I_t - \lambda I_{x'} I_{'}y \bar{v}'^{old})}
    {4(\lambda I_{x'}^2 + \lambda I_{y'}^2 + 4)}
\end{equation}

\begin{equation}
    u'^{new}(x,y) = \frac
    {(\lambda I_{y'}^2 \bar{u}'^{old} + 4\bar{u}'^{old} - \lambda I_{x'} I_t - \lambda I_{x'} I_{y'} \bar{v}'^{old})}
    {(\lambda I_{x'}^2 + \lambda I_{y'}^2 + 4)}
\end{equation}

\noindent Now we can introduce terms to try and help us simplify to our end goal. To this end, we will be adding in the terms $\lambda I_{x'}^2\bar{u}'^{old} -\lambda I_{x'}^2\bar{u}'^{old}$. Since the terms cancel out on their own it's the equivalent of adding 0, and thus does not change our definition.

\begin{equation}
    u'^{new}(x,y) = \frac
    {\lambda I_{y'}^2 \bar{u}'^{old} + 4\bar{u}'^{old} - \lambda I_{x'} I_t - \lambda I_{x'} I_{y'} \bar{v}'^{old} + \lambda I_{x'}^2\bar{u}'^{old} - \lambda I_{x'}^2\bar{u}'^{old}}
    {(\lambda I_{x'}^2 + \lambda I_{y'}^2 + 4)}
\end{equation}

\begin{equation}
    u'^{new}(x,y) = \frac
    {\bar{u}'^{old} \bigl( \lambda I_{y'}^2 + 4 + \lambda I_{x'}^2 \bigr) - \lambda I_{x'}^2 \bar{u}'^{old} - \lambda I_{x'} I_{y'} \bar{v}'^{old} - \lambda I_{x'} I_t}
    {(\lambda I_{x'}^2 + \lambda I_{y'}^2 + 4)}
\end{equation}

\begin{equation}
    u'^{new}(x,y) = \bar{u}'^{old} - \frac
    {\lambda I_{x'}^2 \bar{u}'^{old} + \lambda I_{x'} I_{y'} \bar{v}'^{old} + \lambda I_{x'} I_t}
    {(\lambda I_{x'}^2 + \lambda I_{y'}^2 + 4)}
\end{equation}

\noindent As specified before, $I_{y'} = 0$, so we can now fill that in:

\begin{equation}
    u'^{new}(x,y) = \bar{u}'^{old} - \frac
    {\lambda I_{x'}^2 \bar{u}'^{old} + \lambda I_{x'} 0 \bar{v}'^{old} + \lambda I_{x'} I_t}
    {(\lambda I_{x'}^2 + 0 + 4)} = \bar{u}'^{old} - \frac
    {\lambda I_{x'}^2 \bar{u}'^{old} + \lambda I_{x'} I_t}
    {(\lambda I_{x'}^2 + 4)}
\end{equation}

\begin{equation}
    u'^{new}(x,y) = = \bar{u}'^{old} - \frac
    {I_{x'}^2 \bar{u}'^{old} + I_{x'} I_t}
    {( I_{x'}^2 + \frac{4}{\lambda})}
\end{equation}

\noindent ...which matches what we were seeking to reduce to for $u'^{new}(x.y)$. Doing this for $v'^{new}(x,y)$ we would follow a similar path - we would find that:


\begin{equation}
    v'^{new}(x,y) = \frac{1}{4(\lambda I_{x'}^2+\lambda I_{y'}^2 + 4)}\begin{bmatrix}
        -\lambda I_{x'} I_{y'} & \lambda I_{x'}^2 + 4
    \end{bmatrix}\begin{bmatrix}
        4\bar{u}'^{old}-\lambda I_{x'} I_t \\
        4\bar{v}'^{old}-\lambda I_{y'} I_t \\
    \end{bmatrix}
\end{equation}

\begin{equation}
    v'^{new}(x,y) = \frac{1}{4(\lambda I_{x'}^2+\lambda I_{y'}^2 + 4)}
    \bigl(
        (\lambda I_{x'}^2+4)(4\bar{v}^{old}-\lambda I_{y'}I_t)-(\lambda I_{x'}I_{y'})(4\bar{u}^{old}-\lambda I_{x'} I_t)
    \bigr)
\end{equation}

\noindent ...again, we can utilize the specified knowledge that $I_{y'}=0$:

\begin{equation}
    v'^{new}(x,y) = \frac{1}{4(\lambda I_{x'}^2+\lambda 0^2 + 4)}
    \bigl(
        (\lambda I_{x'}^2+4)(4\bar{v}^{old}-\lambda 0I_t)-(\lambda I_{x'}0)(4\bar{u}^{old}-\lambda I_{x'} I_t)
    \bigr)
\end{equation}

\begin{equation}
    v'^{new}(x,y) =
    \frac{1}{4(\lambda I_{x'}^2+ 4)}((\lambda I_{x'}^2+4)(4\bar{v}^{old}))
\end{equation}

\begin{equation}
    v'^{new}(x,y) =
    \frac{4\bar{v}^{old}\lambda I_{x'}^2+16\bar{v}^{old}}
    {4(\lambda I_{x'}^2+ 4)}
\end{equation}

\begin{equation}
    v'^{new}(x,y) = \bar{v}^{old}
    \frac{4\lambda I_{x'}^2+16}
    {4(\lambda I_{x'}^2+ 4)}
\end{equation}

\begin{equation}
    v'^{new}(x,y) = \bar{v}^{old}
    \frac{4(\lambda I_{x'}^2+4)}
    {4(\lambda I_{x'}^2+ 4)}
\end{equation}

\begin{equation}
    v'^{new}(x,y) = \bar{v}^{old}
\end{equation}

\noindent ...thus proving that:

\begin{equation}
    u'^{new}(x,y) = \bar{u}'^{old} - \frac{I_{x'}^2 \bar{u}'^{old} + I_{x'}I_t}{I_x^2+\frac{4}{\lambda}}
\end{equation}

\begin{equation}
    v'^{new}(x,y) = \bar{v}'^{old}
\end{equation}



\section*{Problem 2}

We can represent an object by its boundary, $(x(s),y(s)),0\leq s \leq S$, where $S$ is the length of the object's boundary and $s$ is distance along that boundary from some arbitrary starting point. Combine $x$ and $y$ into a single complex funcion $z(s)=x(s)+jy(s)$. The Discrete Fourier Transform (DFT) of $z$ is:

\begin{equation}
    Z(k) = \sum^{S-1}_{s=0} e^{-2\pi j \frac{ks}{S}} z(s), 0\leq k \leq S-1
\end{equation}

We can use the coefficients $Z(k)$ to represent the object boundary. The limit on $s$ is $S-1$ because for a closed contour $z(S)=z(0)$. The Inverse Discrete Fourier Transform is:

\begin{equation}
    z(s) = \frac{1}{S} \sum_{k=0}^{S-1} e^{+2\pi j \frac{ks}{S}} Z(k), 0 \leq s \leq S-1
\end{equation}

\subsection*{A}

Suppose that the object is translated by $(\Delta x, \Delta y)$, that is, $z'(s)=z(s) + \Delta x + j \Delta y$. How is $z'$'s DFT $Z'(k)$ related to $Z(k)$?


\begin{equation}
    Z(k) = \sum^{S-1}_{s=0} e^{-2*\pi j \frac{ks}{S}} z(s), 0\leq k \leq S-1
\end{equation}

\noindent Which we can define $z'(s)$ as:

\begin{equation}
    z'(s) = z(s) + \Delta x + j \Delta y
\end{equation}

\noindent If we plug this into our original equation, we get...

\begin{equation}
    Z'(k) = \sum_{s=0}^{S-1} e^{-2\pi j \frac{ks}{S}}z(s) + \sum_{s=0}^{S-1} e^{-2\pi j \frac{ks}{S}} (\Delta x + j \Delta y) (1)
\end{equation}

\noindent Here we see that we have a segment that is equivalent to oru defined $Z(k)$, so we can simplify by expressing:

\begin{equation}
    Z(k) + (1) (\Delta x + j \Delta y) \sum_{s=0}^{S-1} e^{-2\pi j \frac{ks}{S}}
\end{equation}

\noindent With $\Delta x$ and $j \Delta y$ isolated, we can use a table of known Fourier Transforms to identify the resulting conversion. Based on our problem's definition $\Delta X$ and $\Delta y$ are both constants, so we can state that:

\begin{equation}
    Z'(k) = Z(k) + (\Delta x + j \Delta y) \sigma(\frac{2 \pi k}{S})
\end{equation}

\noindent ...where $\frac{1}{S}$ acts as our scaling factor.

\subsection*{B}

In this section, we are asked to suppose that the object is scaled by an integer constant $c$, that is $z'(s)=cz(s)$. For simplicity, we are to assume that $S'=S$. How is $Z'(k)$ as the DFT of $z'$ related to $Z(k)$?

\noindent Starting with our definition of $Z(k)$, which is our Fourier Transform of $z(s)$ as defined earlier:

\begin{equation}
    Z(k) = \sum^{S-1}_{s=0} e^{-2\pi j \frac{ks}{S}} z(s), 0\leq k \leq S-1
\end{equation}

\noindent If we then define $z'(s)$ as above, $z'(s)=cz(s)$, we can plug it into our Fourier Transform:

\begin{equation}
    Z'(k) = \sum^{S-1}_{s=0} e^{-2\pi j \frac{ks}{S}} cz(s)
\end{equation}

\noindent Since $c$ is a constant, we know we can pull it in front of the fourier Transform like so:

\begin{equation}
    Z'(k) = c \sum^{S-1}_{s=0} e^{-2\pi j \frac{ks}{S}} z(s) 
\end{equation}

\noindent ...and further simplified:

\begin{equation}
    Z'(k) = c Z(k)
\end{equation}

\noindent ...which shows that multiplying our time series function by a given scalar simply multipies our frequncy domain by the same scalar.


\subsection*{C}

We wish to know what object has $z(s)=\begin{bmatrix}x_0 + R\cos(\frac{2\pi s}{s})\end{bmatrix}+j\begin{bmatrix}y_0 + R \sin(\frac{2\pi s}{s})\end{bmatrix}$. Below we created a graph drawing the resulting shape, and include the code utilized to generate it. Arbitrary values were chosen for $S$, $r$, $x_0$, and $y_0$ for the sake of plotting.

\begin{figure}[H]
    \centering
    \includegraphics[width = 0.65\textwidth]{imgs/prob2_c.png}
    \caption{Our resulting shape}
    \label{fig:prob2-c}
\end{figure}

\begin{python}
    import numpy as np
    from numpy import cos, sin, pi
    import matplotlib.pyplot as plt
    
    figure = plt.figure()
    plt.title("Problem 2C")
    
    S = 10
    r = 4
    x0 = 1
    y0 = 1
    
    theta = [theta for theta in np.arange(0, S, 0.01)]
    X = [
            x0 + r * cos(2*pi*theta)/S
            for theta in theta
        ]
    Y = [
            y0 + r * sin(2*pi*theta)/S
            for theta in theta
        ]
    
    # Plot the results
    plt.plot(X, Y)
    plt.savefig("./imgs/prob2_c.png")
\end{python}

\subsection*{D}

What is $Z(k)$ corresponding to $z(s)$ from Part C? To do this, we begin wtih our $z(s)$:

\begin{equation}
    z(s)=\begin{bmatrix}x_0 + R\cos(\frac{2\pi s}{s})\end{bmatrix}+j\begin{bmatrix}y_0 + R \sin(\frac{2\pi s}{s})\end{bmatrix}
\end{equation}

We can utilize the inverse of Euler's formula; $\cos(x)=\frac{e^{ix}+e^{-ix}}{2}$ and $\sin(t) = \frac{e^{ix}-e^{-ix}}{2x}$. This allows us to expand our starting equation:

\begin{equation}
    z(s)= x_0 + R\frac{e^{j\frac{2\pi s}{S}} + e^{-j\frac{2\pi s}{S}}}{2} + jy_0 + R\frac{e^{j\frac{2\pi s}{S}}-e^{-j\frac{2\pi s}{S}}}{2}
\end{equation}

\begin{equation}
    z(s) = x_0 + jy_0 + \frac{R}{2} \bigl(e^{j\frac{2\pi s}{S}} + e^{-j\frac{2\pi s}{S}} + e^{j\frac{2\pi s}{S}} - e^{-j\frac{2\pi s}{S}}\bigr)
\end{equation}

\begin{equation}
    z(s)= x_0 + jy_0 + \frac{R}{2} \bigl( 2e^{j\frac{2\pi s}{S}} \bigr)
\end{equation}

\begin{equation}
    z(s)= x_0 + jy_0 + Re^{j\frac{2\pi s}{S}}
\end{equation}

\noindent The Discrete Fourier Transform (DFT) from earlier in our problem we can begin to expand this equation now. Starting with:

\begin{equation}
    Z(k) = \sum^{S-1}_{s=0} e^{-2\pi j \frac{ks}{S}} z(s), 0\leq k \leq S-1
\end{equation}

\noindent ...which can lead us to:

\begin{equation}
    Z(k) = \sum^{S-1}_{s=0} e^{-2\pi j \frac{ks}{S}} \bigl( x_0 + jy_0 + Re^{j\frac{2\pi s}{S}} \bigr)
\end{equation}

\noindent ...constants can be pulled out, leaving us with:

\begin{equation}
    Z(k) = \sum^{S-1}_{s=0} e^{-2\pi j \frac{ks}{S}} (x_0 + jy_0) + R\sum^{S-1}_{s=0} e^{-2\pi j \frac{ks}{S}} e^{j\frac{2\pi s}{S}}
\end{equation}

\begin{equation}
    Z(k) = (x_0 + jy_0) \sum^{S-1}_{s=0} e^{-2\pi j \frac{ks}{S}}  + R\sum^{S-1}_{s=0} e^{-j 2 \pi \frac{(k-1)}{S}}
\end{equation}

\noindent We know from a Fourier Transform lookup table we can then convert this to:

\begin{equation}
    Z(k) = (x_0+jy_0)\sigma(k) + R\sigma(k-1)
\end{equation}



\section*{Problem 3}

In this problem, we are looking at Stereo vision via Singular Value Decomposition (SVD). We are told to assume the usual stereo geometry, where the left and right cameras are offset by baseline $\vec{B}$ that is perpendicular to the common focal vector $\vec{F}$. Then the stereo imaging equations are:

\begin{equation}
    \vec{X}_L = \frac{|\vec{F}|^2}{\vec{F}\cdot \vec{X}^W}
\end{equation}

\begin{equation}
    \vec{X}_R = \frac{|\vec{F}|^2}{\vec{F}\cdot \vec{X}^W}
\end{equation}

\noindent In the presence of imaging errors and noise, these equations might not hold exactly. We can approximate them by:

\begin{equation}
    \vec{X}_L-\frac{|\vec{F}|^2}{\vec{F} \cdot \vec{X}^W}
    \bigl(
        \vec{X}^W + \frac{\vec{B}}{2}
    \bigr) \approx \vec{0}
\end{equation}

\begin{equation}
    \vec{X}_R-\frac{|\vec{F}|^2}{\vec{F} \cdot \vec{X}^W}
    \bigl(
        \vec{X}^W + \frac{\vec{B}}{2}
    \bigr) \approx \vec{0}
\end{equation}

\subsection*{A}

First we are tasked with showing that these equations can be written as a $4x4$ matrix operating on a column vector in homogenous coordinates:

\begin{equation}
    \begin{bmatrix}
        -f & 0 & x_L & -f \frac{b}{2}\\
        0 & -f & y_L & 0 \\
        -f & 0 & x_R & -f \frac{b}{2}\\
        0 & -f & y_R & 0 \\
    \end{bmatrix}\begin{bmatrix}
        x^W \\ y^W \\ z^W \\ 1
    \end{bmatrix}
    \approx \vec{0}
\end{equation}

\noindent We start by first rewriting the project equation for the left camera:

\begin{equation}
    \bigl( \vec{F}\cdot\vec{X}^W \bigr) \vec{X}_L - |\vec{F}|^w \bigl( \vec{X}^W + \frac{\vec{B}}{2} \bigr) \approx \vec{0}
\end{equation}

\noindent ...we can then expand the components for each coordinate axis:

\begin{equation}
    f z^W x_L - f^2 x^W - f^2 \frac{b}{2} \approx 0
\end{equation}

\begin{equation}
    f z^W y_L - f^2 y^W \approx 0
\end{equation}

\begin{equation}
    z^W y_R - f y^W \approx 0
\end{equation}

\noindent ...where the bottom equation reduces to $0$, as $z_L = f$. We can then simplify these equations for both the left and right projections by dividing them by $f$ to simplify:

\begin{equation}
    z^W x_L - f x^W - f \frac{b}{2} \approx 0
\end{equation}

\begin{equation}
    z^W y_L - f y^W \approx 0
\end{equation}

\begin{equation}
    z^W x_R - f x^W + f \frac{b}{2} \approx 0
\end{equation}

\begin{equation}
    z^W y_R - f y^W \approx 0
\end{equation}

\noindent ...We can represent this as a matrix:

\begin{equation}
    \begin{bmatrix}
        -f & 0 & x_L & -f \frac{b}{2}\\
        0 & -f & y_L & 0 \\
        -f & 0 & x_R & -f \frac{b}{2}\\
        0 & -f & y_R & 0 \\
    \end{bmatrix}\begin{bmatrix}
        x^W \\ y^W \\ z^W \\ 1
    \end{bmatrix}
    \approx \vec{0}
\end{equation}

\noindent ...which is what we were looking for!

\subsection*{B}

We can use SVD to find the singular vector $\tilde{X}'$ that minimizes $|A\vec{X}|^2$ subject to $|\vec{X}|^2=1$. We wish to express the world point $\vec{X}= \begin{bmatrix}
    x \\ y \\ z
\end{bmatrix}$ in terms of $\tilde{X}' = \begin{bmatrix}
    x' \\ y' \\ z' \\ w'
\end{bmatrix}$.

\noindent For this we can simply say that:

\begin{equation}
    \vec{X}^W = \frac{1}{W'} \tilde{X}' = \begin{bmatrix}
        \frac{x'}{w'} \\ \frac{y'}{w'} \\ \frac{z'}{w'} \\ 1
    \end{bmatrix}
\end{equation}

\subsection*{C}

Here we are tasked to show that as $y_L=y_R$, our answer in part A gives $z^W=\frac{fb}{d}$, where $d$ is the disparity.

\noindent To start, we look at our equations from part A:

\begin{equation}
    z^W x_L - f x^W - f \frac{b}{2} \approx 0
\end{equation}

\begin{equation}
    z^W y_L - f y^W \approx 0
\end{equation}

\begin{equation}
    z^W x_R - f x^W + f \frac{b}{2} \approx 0
\end{equation}

\begin{equation}
    z^W y_R - f y^W \approx 0
\end{equation}

Looking at the above equations, we can simplify the $2^{nd}$ and $4^{th}$ equations; they simplify to $z^Wy - fy^W \approx 0$. If we set $y^W = \frac{z^W}{f}$, then it equals $0$ and can be ignored. Then, looking at equations 1 and 3 and subtracting one of the other:

\begin{equation}
    (x_L-x_R)z^W 0 fb \approx 0
\end{equation}

\noindent ...which expressed differently, shows that:

\begin{equation}
    z^W = \frac{fb}{x_L-x_R}
\end{equation}

\noindent ...and since we defined $d=x_L-x_R$...:

\begin{equation}
    z^W = \frac{fb}{d}
\end{equation}

\noindent ...which is what we set out to prove!


\section*{Problem 4}

In this problem we are presented with a robot which has two main sensors for vision - an infra-red sensor, and a LiDAR sensor.

We are tasked with having brief discussions of one to three challenges with LiDAR vision alone, infra-red vision alone, the combination of the two, and challening situations that require additional vision capacities.

\subsection*{LiDAR vision alone}

First, we will explore the challenges we might encounter with solely using LiDAR on our robot.

\begin{itemize}
    \item \textbf{Object Detection} - LiDAR creates a set of points that represent distances. IF we are utilizing a planar LiDAR - IE a laser that sweeps at a set plane, we only have a two dimensional representation of those distances. These perimeters are only comprised of the presenting-face/edge of the object, and nowhere near complete. From these perimeters it is difficult to assign identity to any of them. If, instead, we have a 3d LiDAR sensor capable of creating point clouds, we can begin to better identify objects, but it is still difficult. We lack the detection of fine details, only its face-presenting outline, and its surface texture (assuming high enough resolution). similarly, this lack of details can be especially damning when like objects are overlayed or clumped together - it may be difficult to impossible to discern material differences such it would present as a singular object. For many applications this is unsuitable.
    \item \textbf{Difficulty with sunlight} - LiDAR works by firing a laser (or a spread of them) and then timing the return of that laser. This means that LiDAR can be directly influenced and affected by the presence of bright lights, especially sunlight. By no means is LiDAR unusable during the day - there are units built for such applications. There is, however, times when sunlight not only saturates your results thus limiting your distance-range, but can also outright interfere with the sensor. Imagine our robot driving into the sunset with the sensor oriented towards the sun; the sensor's reading will likely be shortened, or extremely insuated with noise.
    \item \textbf{Affected by weather} - If we expect our robot to operate in outdoor environments, then we must also note that the weather can heavily affect the performance of the sensor. Heavy rain or fog can dramatically shorten the range of the sensor, scattering the fired laser. Snow fall can actually reflect or absorb the laser oddly, resulting in incorrect readings for snow covered objects.
\end{itemize}


\subsection*{Infra-red vision alone}

\begin{itemize}
    \item \textbf{Detail obscurity} - Since we are reading the emission of infra-red light from the object, it is heavily influenced by the emissivity of the material and its active temperature. Certain materials block or absorb infra-red, resulting in a vision-blocker. This weakness of infra-red vision is utilized in military applications, for instance. Along the same line, details of objects that are emitting can be obscured and lost completely. For instance, a human's shape and outline can be discerned, but it is difficult to impossible to distinguish fine details such as expression.
    \item \textbf{Shading and edge detection} - objects tend to emit infra-red uniformly; as a result there is no shading to allows us to estimate surface orientation. This means orientation and identification is difficult.
    \item \textbf{Repeatability} - Since infra-red is affected by the temperature of the object, objects can be represented as completely unrecognizable shades and colors simply because of different ambient or object temperatures.
\end{itemize}

\subsection*{Benefits of imaging with both LiDAR and infra-red vision}

\begin{itemize}
    \item \textbf{Sunlight agnostic} - As mentioned earlier, LiDAR has issues with sunlight saturated environments and situations. Infra-red does not have this issue, allowing our robot to easily use vision to safely navigate into the sunset.
    \item \textbf{Protection against weather} - LiDAR has significant issue in snow, rain, and fog. While fog, if thick enough, can still block vision of infra-red, in light fog and the other scenarios infra-red will not be heavily affected and will help better inform our robot of its environment for navigation.
    \item \textbf{Repeatability on identification} - Infra-red has issues with a lack of shading and coloring difference due to difference in temperatures. LiDAR can better and reliably detect surface textures and orientation, allowing better detection with the combined sensors.
\end{itemize}

\subsection*{What other vision options can we benefit from?}

\begin{itemize}
    \item \textbf{RGB Camera} - The most common vision sensor, an RGB camera would grant us color, shading, and significant improvements in details on objects such that we would be able to more easily identify objects within our environment, such as reading signs or warning labels.
    \item \textbf{X-Ray} - There are several situations where we need to detect what's \textit{underneath} a given surface or material to correctly identify problems that we could be sending our robot out to repair. X-Ray sensors allow us to see through certain materials, allowing us insight that other sensors would otherwise be completely ignorant of.
    \item \textbf{Sonar} - If our robot is required to work in an underwater situation, our available sensors of LiDAR and infra-red have limited range and can be deterimental to . Traditionally we can achieve a far greater range of detection with sonar.
\end{itemize}


\end{document}